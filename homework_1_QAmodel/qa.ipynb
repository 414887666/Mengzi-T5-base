{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6928025a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'context': 'ç¬¬35é›†é›ªè§ç¼“ç¼“å¼ å¼€çœ¼ç›ï¼Œæ™¯å¤©åˆæƒŠåˆå–œä¹‹é™…ï¼Œé•¿å¿å’Œç´«è±çš„ä»™èˆ¹é©¶è‡³ï¼Œè§ä¼—äººæ— æ™ï¼Œä¹Ÿååˆ†é«˜å…´ã€‚ä¼—äººç™»èˆ¹ï¼Œç”¨å°½åˆåŠ›æŠŠè‡ªèº«çš„çœŸæ°”å’Œæ°´åˆ†è¾“ç»™å¥¹ã€‚é›ªè§ç»ˆäºé†’è¿‡æ¥äº†ï¼Œä½†å´ä¸€è„¸æœ¨ç„¶ï¼Œå…¨æ— ååº”ã€‚ä¼—äººå‘å¸¸èƒ¤æ±‚åŠ©ï¼Œå´å‘ç°äººä¸–ç•Œç«Ÿæ²¡æœ‰é›ªè§çš„èº«ä¸–çºªå½•ã€‚é•¿å¿è¯¢é—®æ¸…å¾®çš„èº«ä¸–ï¼Œæ¸…å¾®è¯­å¸¦åŒå…³è¯´ä¸€åˆ‡ä¸Šäº†å¤©ç•Œä¾¿æœ‰ç­”æ¡ˆã€‚é•¿å¿é©¾é©¶ä»™èˆ¹ï¼Œä¼—äººå†³å®šç«‹é©¬åŠ¨èº«ï¼Œå¾€å¤©ç•Œè€Œå»ã€‚ä¼—äººæ¥åˆ°ä¸€è’å±±ï¼Œé•¿å¿æŒ‡å‡ºï¼Œé­”ç•Œå’Œå¤©ç•Œç›¸è¿ã€‚ç”±é­”ç•Œè¿›å…¥é€šè¿‡ç¥é­”ä¹‹äº•ï¼Œä¾¿å¯ç™»å¤©ã€‚ä¼—äººè‡³é­”ç•Œå…¥å£ï¼Œä»¿è‹¥ä¸€é»‘è‰²çš„è™è æ´ï¼Œä½†å§‹ç»ˆæ— æ³•è¿›å…¥ã€‚åæ¥èŠ±æ¥¹å‘ç°åªè¦æœ‰ç¿…è†€ä¾¿èƒ½é£å…¥ã€‚äºæ˜¯æ™¯å¤©ç­‰äººæ‰“ä¸‹è®¸å¤šä¹Œé¸¦ï¼Œæ¨¡ä»¿é‡æ¥¼çš„ç¿…è†€ï¼Œåˆ¶ä½œæ•°å¯¹ç¿…è†€çŠ¶å·¨ç‰©ã€‚åˆšä½©æˆ´åœ¨èº«ï¼Œä¾¿è¢«å¸å…¥æ´å£ã€‚ä¼—äººæ‘”è½åœ¨åœ°ï¼ŒæŠ¬å¤´å‘ç°é­”ç•Œå®ˆå«ã€‚æ™¯å¤©å’Œä¼—é­”å¥—äº¤æƒ…ï¼Œè‡ªç§°å’Œé­”å°Šé‡æ¥¼ç›¸ç†Ÿï¼Œä¼—é­”ä¸ç†ï¼Œæ‰“äº†èµ·æ¥ã€‚', 'answer': 'ç¬¬35é›†', 'question': 'ä»™å‰‘å¥‡ä¾ ä¼ 3ç¬¬å‡ é›†ä¸Šå¤©ç•Œ', 'id': 0}, {'context': 'é€‰æ‹©ç‡ƒæ°”çƒ­æ°´å™¨æ—¶ï¼Œä¸€å®šè¦å…³æ³¨è¿™å‡ ä¸ªé—®é¢˜ï¼š1ã€å‡ºæ°´ç¨³å®šæ€§è¦å¥½ï¼Œä¸èƒ½å‡ºç°å¿½çƒ­å¿½å†·çš„ç°è±¡2ã€å¿«é€Ÿåˆ°è¾¾è®¾å®šçš„éœ€æ±‚æ°´æ¸©3ã€æ“ä½œè¦æ™ºèƒ½ã€æ–¹ä¾¿4ã€å®‰å…¨æ€§è¦å¥½ï¼Œè¦è£…æœ‰å®‰å…¨æŠ¥è­¦è£…ç½® å¸‚åœºä¸Šç‡ƒæ°”çƒ­æ°´å™¨å“ç‰Œä¼—å¤šï¼Œè´­ä¹°æ—¶è¿˜éœ€å¤šåŠ å¯¹æ¯”å’Œä»”ç»†é‰´åˆ«ã€‚æ–¹å¤ªä»Šå¹´ä¸»æ‰“çš„ç£åŒ–æ’æ¸©çƒ­æ°´å™¨åœ¨ä½¿ç”¨ä½“éªŒæ–¹é¢åšäº†å…¨é¢å‡çº§ï¼š9ç§’é€Ÿçƒ­ï¼Œå¯å¿«é€Ÿè¿›å…¥æ´—æµ´æ¨¡å¼ï¼›æ°´æ¸©æŒä¹…ç¨³å®šï¼Œä¸ä¼šå‡ºç°å¿½çƒ­å¿½å†·çš„ç°è±¡ï¼Œå¹¶é€šè¿‡æ°´é‡ä¼ºæœæŠ€æœ¯å°†å‡ºæ°´æ¸©åº¦ç²¾ç¡®æ§åˆ¶åœ¨Â±0.5â„ƒï¼Œå¯æ»¡è¶³å®¶é‡Œå®è´æ•æ„Ÿè‚Œè‚¤æ´—æŠ¤éœ€æ±‚ï¼›é…å¤‡COå’ŒCH4åŒæ°”ä½“æŠ¥è­¦è£…ç½®æ›´å®‰å…¨ï¼ˆå¸‚åœºä¸Šä¸€èˆ¬å¤šä¸ºCOå•æ°”ä½“æŠ¥è­¦ï¼‰ã€‚å¦å¤–ï¼Œè¿™æ¬¾çƒ­æ°´å™¨è¿˜æœ‰æ™ºèƒ½WIFIäº’è”åŠŸèƒ½ï¼Œåªéœ€ä¸‹è½½ä¸ªæ‰‹æœºAPPå³å¯ç”¨æ‰‹æœºè¿œç¨‹æ“ä½œçƒ­æ°´å™¨ï¼Œå®ç°ç²¾å‡†è°ƒèŠ‚æ°´æ¸©ï¼Œæ»¡è¶³å®¶äººå¤šæ ·åŒ–çš„æ´—æµ´éœ€æ±‚ã€‚å½“ç„¶æ–¹å¤ªçš„ç£åŒ–æ’æ¸©ç³»åˆ—ä¸»è¦çš„æ˜¯å¢åŠ ç£åŒ–åŠŸèƒ½ï¼Œå¯ä»¥æœ‰æ•ˆå¸é™„æ°´ä¸­çš„é“é”ˆã€é“å±‘ç­‰å¾®å°æ‚è´¨ï¼Œé˜²æ­¢ç»†èŒæ»‹ç”Ÿï¼Œä½¿æ²æµ´æ°´è´¨æ›´æ´å‡€ï¼Œé•¿æœŸä½¿ç”¨ç£åŒ–æ°´æ²æµ´æ›´åˆ©äºèº«ä½“å¥åº·ã€‚', 'answer': 'æ–¹å¤ª', 'question': 'ç‡ƒæ°”çƒ­æ°´å™¨å“ªä¸ªç‰Œå­å¥½', 'id': 1}, {'context': 'è¿ˆå…‹å°”.ä¹”ä¸¹åœ¨NBAæ‰“äº†15ä¸ªèµ›å­£ã€‚ä»–åœ¨84å¹´è¿›å…¥nbaï¼ŒæœŸé—´åœ¨1993å¹´10æœˆ6æ—¥ç¬¬ä¸€æ¬¡é€€å½¹æ”¹æ‰“æ£’çƒï¼Œ95å¹´3æœˆ18æ—¥é‡æ–°å›å½’ï¼Œåœ¨99å¹´1æœˆ13æ—¥ç¬¬äºŒæ¬¡é€€å½¹ï¼Œåäº2001å¹´10æœˆ31æ—¥å¤å‡ºï¼Œåœ¨03å¹´æœ€ç»ˆé€€å½¹ã€‚è¿ˆå…‹å°”Â·ä¹”ä¸¹ï¼ˆMichael Jordanï¼‰ï¼Œ1963å¹´2æœˆ17æ—¥ç”Ÿäºçº½çº¦å¸ƒé²å…‹æ—ï¼Œç¾å›½è‘—åç¯®çƒè¿åŠ¨å‘˜ï¼Œå¸èŒå¾—åˆ†åå«ï¼Œå†å²ä¸Šæœ€ä¼Ÿå¤§çš„ç¯®çƒè¿åŠ¨å‘˜ã€‚1984å¹´çš„NBAé€‰ç§€å¤§ä¼šï¼Œä¹”ä¸¹åœ¨é¦–è½®ç¬¬3é¡ºä½è¢«èŠåŠ å“¥å…¬ç‰›é˜Ÿé€‰ä¸­ã€‚ 1986-87èµ›å­£ï¼Œä¹”ä¸¹åœºå‡å¾—åˆ°37.1åˆ†ï¼Œé¦–æ¬¡è·å¾—åˆ†ç‹ç§°å·ã€‚1990-91èµ›å­£ï¼Œä¹”ä¸¹è¿å¤ºå¸¸è§„èµ›MVPå’Œæ€»å†³èµ›MVPç§°å·ï¼Œç‡é¢†èŠåŠ å“¥å…¬ç‰›é¦–æ¬¡å¤ºå¾—NBAæ€»å† å†›ã€‚ 1997-98èµ›å­£ï¼Œä¹”ä¸¹è·å¾—ä¸ªäººèŒä¸šç”Ÿæ¶¯ç¬¬10ä¸ªå¾—åˆ†ç‹ï¼Œå¹¶ç‡é¢†å…¬ç‰›é˜Ÿç¬¬å…­æ¬¡å¤ºå¾—æ€»å† å†›ã€‚2009å¹´9æœˆ11æ—¥ï¼Œä¹”ä¸¹æ­£å¼å…¥é€‰NBAåäººå ‚ã€‚', 'answer': '15ä¸ª', 'question': 'ä¹”ä¸¹æ‰“äº†å¤šå°‘ä¸ªèµ›å­£', 'id': 2}, {'context': 'æœè¾¾æ˜Œé‡åº†æ›™å…‰ç”·ç§‘åŒ»é™¢ä¸´åºŠä¸“å®¶,æ›™å…‰ååŒ»å ‚ä¸­å¿ƒä¸“å®¶,ä»äº‹æ³Œå°¿(ç”·ç§‘)å·¥ä½œ30å¤šå¹´,æ“…é•¿æ³Œå°¿ç”Ÿæ®–è‚¿ç˜¤ã€å‰åˆ—è…ºå¢ç”Ÿã€å°¿è·¯ç»“çŸ³ç”·æ€§ç”Ÿæ®–æ•´å½¢ç­‰ç–‘éš¾ç–¾ç—…è¯Šæ²»,ç‹¬ç«‹å¼€å±•å‰åˆ—è…ºæ±½åŒ–ç”µåˆ‡æ‰‹æœ¯åƒä½™ä¾‹,æŠ€æœ¯ç²¾æ¹›,ç»éªŒä¸°å¯Œã€‚...[è¯¦æƒ…]', 'answer': 'æ›™å…‰ç”·ç§‘åŒ»é™¢', 'question': 'é‡åº†å‰²åŒ…çš®å“ªå¥½', 'id': 3}, {'context': 'å›½æ°‘å¼Ÿå¼Ÿå´ç£Šä½œä¸ºä»£è¨€äººå‡ºå¸­æŸå“ç‰Œæ´»åŠ¨,ä¸è§„åˆ™æ¡çº¹è¡¬è¡«å†…æ­ç»¿è‰²Tæ¤,å±‚æ¬¡æ„Ÿçš„æ··æ­æ½®é…·èŒƒåè¶³åˆä¸å¤±æ´»åŠ›ã€‚äº®ç»¿è‰²çš„ç©¿æ­ä¸€æ‰«æ²‰é—·,å¯ä»¥è¯´æ˜¯ç‚çƒ­å¤æ—¥é‡Œçš„ä¸€é˜µæ¸…é£äº†ï½ ä¸‹é¢å’Œå°ç¼–ä¸€èµ·æ¥çœ‹çœ‹å§!|æ®æ‚‰ã€Šæ–—ç ´è‹ç©¹ã€‹å´ç£Šæ—å…â€œæ–—æ°”â€é›†ç»“,å„è´Ÿç›”ç”²è«æ¬ºå°‘å¹´ç©·,ç”µè§†å‰§ã€Šæ–—ç ´è‹ç©¹ã€‹æ­£åœ¨æ‹æ‘„ä¸­,é¢„è®¡äº2017å¹´å¹´åº•ä¸Šæ˜ æ’­å‡ºã€‚|ä»¥ä¸Šå°±æ˜¯å´ç£Šå‡ºå¸­æ´»åŠ¨ç…§çš„ç›¸å…³æ¶ˆæ¯,(åŸå›¾æ¥æºäºæ–°æµªå¾®åš,å¦‚æœ‰ä¾µæƒè¯·å‘é‚®ä»¶ yule@52pk.comè”ç³»åˆ é™¤)æ›´å¤šç›¸å…³æ¶ˆæ¯,è¯·æŒç»­å…³æ³¨52PKå¨±ä¹é¢‘é“ http://yule.52pk.com/ ã€‚|ä¸Šä¸€ç¯‡:åˆ˜äº¦è²é™ˆä¹”æ©è¢«è¯„ä¸ºæœ€ç¾ä¼´å¨˜ éƒ½æ˜¯è¡Œèµ°çš„æŠ¢é•œç‹è€…ä¸‹ä¸€ç¯‡:ä¸ƒåäºŒå±‚å¥‡æ¥¼æˆéƒ½å½•åˆ¶ å´äº¦å‡¡é¢–å®å˜èº«æœåŠ¡å‘˜èŒç¿»å¤©', 'answer': '2017å¹´å¹´åº•', 'question': 'å´ç£Šæ–—ç ´è‹ç©¹ä¸Šæ˜ æ—¶é—´', 'id': 4}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AutoTokenizer\n",
    "\n",
    "\n",
    "# 1. åŠ è½½ é¢„è®­ç»ƒæ¨¡å‹ å’Œ åˆ†è¯å™¨\n",
    "model_name=\"langboat/mengzi-t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# 2. è¯»å–æ•°æ®é›†\n",
    "def load_json(file_path):\n",
    "    data=[]\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "train_data = load_json('data/train.json')\n",
    "valid_data = load_json('data/dev.json')\n",
    "\n",
    "print(train_data[:5])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "208aed91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14520\n",
      "984\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9706bb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14520, 4)\n",
      "Dataset({\n",
      "    features: ['context', 'answer', 'question', 'id'],\n",
      "    num_rows: 14520\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 3. è½¬æ¢ä¸ºHUGGINGFACEæ ¼å¼\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "train_dataset=Dataset.from_list(train_data)\n",
    "valid_dataset=Dataset.from_list(valid_data)\n",
    "print(train_dataset.shape)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4567c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14520/14520 [00:09<00:00, 1552.31 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 984/984 [00:00<00:00, 1588.93 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask', 'labels']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. é¢„å¤„ç†\n",
    "# æ‹¼æ¥questionå’Œcontextä½œä¸ºè¾“å…¥ï¼Œanswerä½œä¸ºè¾“å‡ºï¼Œè®­ç»ƒæ¨¡å‹\n",
    "\n",
    "max_input_length = 512\n",
    "max_output_length = 64\n",
    "\n",
    "def preprocess_function(data):\n",
    "    # æ‹¼æ¥questionå’Œcontextä½œä¸ºè¾“å…¥\n",
    "    inputs = [\"question: \" + q + \" context: \" + c for q, c in zip(data[\"question\"], data[\"context\"])]\n",
    "    # è½¬æ¢ä¸ºtoken_id\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, \n",
    "        max_length=max_input_length, \n",
    "        padding=\"max_length\", \n",
    "        truncation=True\n",
    "        )\n",
    "    # æ ‡ç­¾\n",
    "    labels = tokenizer(\n",
    "        data[\"answer\"], \n",
    "        max_length=max_output_length, \n",
    "        padding=\"max_length\", \n",
    "        truncation=True\n",
    "        )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# è°ƒç”¨é¢„å¤„ç†å‡½æ•°ï¼Œå°†åŸå§‹æ–‡æœ¬æ•°æ®è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥ï¼Œinput_idså’Œattention_maskï¼Œä»¥åŠlabels\n",
    "train_datasets = train_dataset.map(\n",
    "    preprocess_function, \n",
    "    batched=True, \n",
    "    remove_columns=train_dataset.column_names\n",
    "    )\n",
    "valid_datasets = valid_dataset.map(\n",
    "    preprocess_function, \n",
    "    batched=True, \n",
    "    remove_columns=valid_dataset.column_names\n",
    "    )\n",
    "print(train_datasets.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f27a7080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "# 5. æ•°æ®æ”¶é›†å™¨ (DataCollatorForSeq2Seq)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "# 6. è¯„ä»·æŒ‡æ ‡ (BLEU)\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # trainerä¼šæŠŠæ¯ä¸€è½®çš„ç»“æœä¼ ç»™compute_metrics\n",
    "    # eval_predåŒ…å«ä¸¤ä¸ªå…ƒç´ ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯æ¨¡å‹é¢„æµ‹çš„ç»“æœï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯æ ‡ç­¾\n",
    "    predictions, labels = eval_pred\n",
    "    # æŠŠtoken idè½¬æ¢ä¸ºæ–‡æœ¬\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # åˆ†è¯ (BLEU éœ€è¦ä»¥è¯ä¸ºå•ä½)\n",
    "    decoded_preds = [list(jieba.cut(pred)) for pred in decoded_preds]\n",
    "    decoded_labels = [[list(jieba.cut(label))] for label in decoded_labels]\n",
    "\n",
    "    result = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {\"bleu\": result[\"bleu\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecda937e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuzih\\AppData\\Local\\Temp\\ipykernel_43836\\489468104.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./t5-qa-output\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# ğŸ”¹ 8. Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_datasets,\n",
    "    eval_dataset=valid_datasets,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cedc937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1816' max='5445' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1816/5445 13:43:25 < 27:27:18, 0.04 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='115' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [115/123 58:02 < 04:04, 0.03 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 7.11 GiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 11.29 GiB is allocated by PyTorch, and 2.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# ğŸ”¹ 10. è®­ç»ƒå®Œæˆåï¼Œä¿å­˜æ¨¡å‹\u001b[39;00m\n\u001b[0;32m      4\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./t5-qa-finetuned\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\transformers\\lib\\site-packages\\transformers\\trainer.py:2328\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2326\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\transformers\\lib\\site-packages\\transformers\\trainer.py:2788\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2785\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2787\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 2788\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\n\u001b[0;32m   2790\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m   2793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[0;32m   2794\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\transformers\\lib\\site-packages\\transformers\\trainer.py:3227\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[0;32m   3225\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[1;32m-> 3227\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3228\u001b[0m     is_new_best_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_best_metric(metrics\u001b[38;5;241m=\u001b[39mmetrics, trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m   3230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_strategy \u001b[38;5;241m==\u001b[39m SaveStrategy\u001b[38;5;241m.\u001b[39mBEST:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\transformers\\lib\\site-packages\\transformers\\trainer.py:3176\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[1;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[0;32m   3175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 3176\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   3179\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\transformers\\lib\\site-packages\\transformers\\trainer.py:4469\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4466\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   4468\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 4469\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4470\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4472\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   4473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   4474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4479\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   4480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\transformers\\lib\\site-packages\\transformers\\trainer.py:4692\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4690\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function(logits)\n\u001b[0;32m   4691\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_eval_metrics \u001b[38;5;129;01mor\u001b[39;00m description \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 4692\u001b[0m         \u001b[43mall_preds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4694\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function(labels)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\transformers\\lib\\site-packages\\transformers\\trainer_pt_utils.py:315\u001b[0m, in \u001b[0;36mEvalLoopContainer.add\u001b[1;34m(self, tensors)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_nested_concat \u001b[38;5;28;01melse\u001b[39;00m [tensors]\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_nested_concat:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m \u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors\u001b[38;5;241m.\u001b[39mappend(tensors)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\transformers\\lib\\site-packages\\transformers\\trainer_pt_utils.py:129\u001b[0m, in \u001b[0;36mnested_concat\u001b[1;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(new_tensors), (\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    127\u001b[0m     )\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index\u001b[38;5;241m=\u001b[39mpadding_index)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\transformers\\lib\\site-packages\\transformers\\trainer_pt_utils.py:129\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(new_tensors), (\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    127\u001b[0m     )\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index\u001b[38;5;241m=\u001b[39mpadding_index)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\transformers\\lib\\site-packages\\transformers\\trainer_pt_utils.py:131\u001b[0m, in \u001b[0;36mnested_concat\u001b[1;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_concat(t, n, padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_pad_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, Mapping):\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\n\u001b[0;32m    134\u001b[0m         {k: nested_concat(t, new_tensors[k], padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    135\u001b[0m     )\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\transformers\\lib\\site-packages\\transformers\\trainer_pt_utils.py:89\u001b[0m, in \u001b[0;36mtorch_pad_and_concatenate\u001b[1;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[0;32m     86\u001b[0m tensor2 \u001b[38;5;241m=\u001b[39m atleast_1d(tensor2)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Let's figure out the new shape\u001b[39;00m\n\u001b[0;32m     92\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m (tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mmax\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 7.11 GiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 11.29 GiB is allocated by PyTorch, and 2.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "# ğŸ”¹ 10. è®­ç»ƒå®Œæˆåï¼Œä¿å­˜æ¨¡å‹\n",
    "trainer.save_model(\"./t5-qa-finetuned\")\n",
    "tokenizer.save_pretrained(\"./t5-qa-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd797ada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
